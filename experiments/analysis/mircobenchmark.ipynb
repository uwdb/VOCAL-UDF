{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "project_root = \"/home/ubuntu/VOCAL-UDF/\"\n",
    "\n",
    "config = yaml.safe_load(open(os.path.join(project_root, \"configs\", \"config.yaml\"), \"r\"))\n",
    "\n",
    "import re\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NL To DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nl_to_dsl(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name):\n",
    "    num_correct = 0\n",
    "    num_correct_98 = 0\n",
    "    num_total = 0\n",
    "    failed_scores = []\n",
    "    for query_class_name in query_class_names:\n",
    "        for run_id in run_ids:\n",
    "            for question_id in question_ids:\n",
    "                num_total += 1\n",
    "                try:\n",
    "                    with open(os.path.join(config['log_dir'], \"nl_to_dsl\", dataset, query_class_name, vocal_udf_config_name, f\"qid={question_id}-run={run_id}.log\"), \"r\") as f:\n",
    "                        lines = f.readlines()\n",
    "                    f1_score = -1\n",
    "                    for line in lines:\n",
    "                        if \"F1 score:\" in line:\n",
    "                            f1_score_pattern = r\"F1 score: ([0-9.]+)\"\n",
    "                            match = re.search(f1_score_pattern, line)\n",
    "                            f1_score = float(match.group(1))\n",
    "                            break\n",
    "                    if f1_score == -1:\n",
    "                        print(f\"failed task: qid={question_id}-run={run_id}\")\n",
    "                        f1_score = 0\n",
    "                    if f1_score == 1:\n",
    "                        num_correct += 1\n",
    "                    else:\n",
    "                        failed_scores.append(f1_score)\n",
    "                        if f1_score < 0.98:\n",
    "                            print(f\"failed task: qid={question_id}-run={run_id}\")\n",
    "                    if f1_score >= 0.98:\n",
    "                        if f1_score < 1:\n",
    "                            print(f\"correct (1>f1>=0.98) task: qid={question_id}-run={run_id}\")\n",
    "                        num_correct_98 += 1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    print(f\"num_total={num_total}, num_correct={num_correct/num_total}, num_correct_98={num_correct_98/num_total}\")\n",
    "    failed_scores.sort(reverse = True)\n",
    "    print(f\"failed_scores={failed_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct (1>f1>=0.98) task: qid=1-run=0\n",
      "correct (1>f1>=0.98) task: qid=2-run=0\n",
      "correct (1>f1>=0.98) task: qid=3-run=0\n",
      "correct (1>f1>=0.98) task: qid=5-run=0\n",
      "correct (1>f1>=0.98) task: qid=6-run=0\n",
      "correct (1>f1>=0.98) task: qid=9-run=0\n",
      "correct (1>f1>=0.98) task: qid=29-run=0\n",
      "correct (1>f1>=0.98) task: qid=1-run=1\n",
      "correct (1>f1>=0.98) task: qid=2-run=1\n",
      "correct (1>f1>=0.98) task: qid=3-run=1\n",
      "correct (1>f1>=0.98) task: qid=5-run=1\n",
      "correct (1>f1>=0.98) task: qid=6-run=1\n",
      "correct (1>f1>=0.98) task: qid=9-run=1\n",
      "correct (1>f1>=0.98) task: qid=1-run=2\n",
      "correct (1>f1>=0.98) task: qid=2-run=2\n",
      "correct (1>f1>=0.98) task: qid=3-run=2\n",
      "correct (1>f1>=0.98) task: qid=5-run=2\n",
      "correct (1>f1>=0.98) task: qid=6-run=2\n",
      "correct (1>f1>=0.98) task: qid=9-run=2\n",
      "num_total=90, num_correct=0.7888888888888889, num_correct_98=1.0\n",
      "failed_scores=[0.9994895354772844, 0.9994895354772844, 0.9994895354772844, 0.9993861264579497, 0.9993861264579497, 0.9993861264579497, 0.9991673605328892, 0.9991673605328892, 0.9991673605328892, 0.9991659716430359, 0.9991659716430359, 0.9991659716430359, 0.9982847341337907, 0.9982847341337907, 0.9982847341337907, 0.9973614775725593, 0.9973614775725593, 0.9973614775725593, 0.9845722300140253]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"clevrer\"\n",
    "query_class_names = [\n",
    "    \"3_new_udfs_labels\",\n",
    "]\n",
    "question_ids = list(range(30))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=True-pretrained_models=False-ntrain_distill=100-nselection_samples=500-selection=both-budget=20-llm_method=gpt\"\n",
    "\n",
    "eval_nl_to_dsl(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct (1>f1>=0.98) task: qid=1-run=0\n",
      "correct (1>f1>=0.98) task: qid=1-run=1\n",
      "correct (1>f1>=0.98) task: qid=1-run=2\n",
      "failed task: qid=2-run=0\n",
      "correct (1>f1>=0.98) task: qid=6-run=0\n",
      "correct (1>f1>=0.98) task: qid=6-run=1\n",
      "correct (1>f1>=0.98) task: qid=6-run=2\n",
      "num_total=90, num_correct=0.9222222222222223, num_correct_98=0.9888888888888889\n",
      "failed_scores=[0.9925925925925926, 0.9925925925925926, 0.9925925925925926, 0.9868766404199476, 0.9868766404199476, 0.9868766404199476, 0.5815899581589957]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cityflow\"\n",
    "query_class_names = [\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=1-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\",\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=2-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\"\n",
    "]\n",
    "question_ids = list(range(15))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt\"\n",
    "\n",
    "eval_nl_to_dsl(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=0.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=1.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=0-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=1-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=2-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=3-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=4-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=5-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=6-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=7-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=8-run=2.log'\n",
      "[Errno 2] No such file or directory: '/home/ubuntu/VOCAL-UDF/logs/nl_to_dsl/charades/unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2/ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt/qid=9-run=2.log'\n",
      "num_total=90, num_correct=0.03333333333333333, num_correct_98=0.03333333333333333\n",
      "failed_scores=[]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"charades\"\n",
    "query_class_names = [\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2\",\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2\",\n",
    "    \"unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2\"\n",
    "]\n",
    "question_ids = list(range(10))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt\"\n",
    "\n",
    "eval_nl_to_dsl(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposing UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_udf_name(dataset, udf_name):\n",
    "    udf_name = udf_name.replace(\" \", \"\").replace(\"_\", \"\").lower()\n",
    "    # location_bottom_left, behind_and_near, in_front_of, behind_left_of, far_left_of, behind_and_left_of, near_and_right_of,\n",
    "    if dataset == \"clevrer\":\n",
    "        if udf_name in [\"materialmetal\", \"madeofmetal\"]:\n",
    "            udf_name = \"metal\"\n",
    "        elif udf_name in [\"shapecylinder\"]:\n",
    "            udf_name = \"cylinder\"\n",
    "        elif udf_name in [\"coloryellow\"]:\n",
    "            udf_name = \"yellow\"\n",
    "        elif udf_name in [\"colorpurple\"]:\n",
    "            udf_name = \"purple\"\n",
    "        elif udf_name in [\"colorcyan\"]:\n",
    "            udf_name = \"cyan\"\n",
    "        elif udf_name in [\"colorbrown\"]:\n",
    "            udf_name = \"brown\"\n",
    "        elif udf_name in [\"locationright\"]:\n",
    "            udf_name = \"right\"\n",
    "        elif udf_name in [\"locationbottom\"]:\n",
    "            udf_name = \"bottom\"\n",
    "        elif udf_name in [\"movesinfrontof\", \"movinginfrontof\", \"infrontof\"]:\n",
    "            udf_name = \"frontof\"\n",
    "        elif udf_name in [\"farfrom\", \"farawayfrom\", \"faraway\"]:\n",
    "            udf_name = \"far\"\n",
    "        elif udf_name in [\"nearof\"]:\n",
    "            udf_name = \"near\"\n",
    "        elif udf_name in [\"behindof\"]:\n",
    "            udf_name = \"behind\"\n",
    "        elif udf_name in [\"shapecylindrical\"]:\n",
    "            udf_name = \"cylinder\"\n",
    "    elif dataset == \"cityflow\":\n",
    "        # right_of, left_of, pickup, in_front_of_white, suv_and_red, white_sedan, moves_in_front_of, color_blue, color_red,\n",
    "        if udf_name in [\"colorred\"]:\n",
    "            udf_name = \"red\"\n",
    "        elif udf_name in [\"colorblue\"]:\n",
    "            udf_name = \"blue\"\n",
    "        elif udf_name in [\"rightof\", \"torightof\"]:\n",
    "            udf_name = \"totherightof\"\n",
    "        elif udf_name in [\"leftof\"]:\n",
    "            udf_name = \"totheleftof\"\n",
    "        elif udf_name in [\"movesinfrontof\"]:\n",
    "            udf_name = \"infrontof\"\n",
    "        elif udf_name in [\"pickup\"]:\n",
    "            udf_name = \"pickuptruck\"\n",
    "    elif dataset == \"charades\":\n",
    "        # inside, inside_of, eating_from, inside_and_interacting_with, inside_while_drinking_from, inside_while_drinking, drinking_from_inside, beneath_and_wearing, moving_behind\n",
    "        if udf_name in [\"inside\", \"insideof\"]:\n",
    "            udf_name = \"in\"\n",
    "        elif udf_name in [\"eatingfrom\"]:\n",
    "            udf_name = \"eating\"\n",
    "        elif udf_name in [\"mobingbehind\"]:\n",
    "            udf_name = \"behind\"\n",
    "    return udf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_proposing_udfs(dataset, query_class_names, num_new_udf_list, question_ids, run_ids, vocal_udf_config_name):\n",
    "    # Is the system able to propose UDFs when needed?\n",
    "    # When does our approach work? When does it fail?\n",
    "    # What UDFs does the system propose?\n",
    "    # Same 90 queries, analyze how well the proposed UDFs match with the ground-truth\n",
    "    # 1. For every proposed UDF, how to define \"match\"?\n",
    "    # 2. When does it over-proposes?\n",
    "    # 3. When does it under-proposes?\n",
    "    # 4. What's the average number of UDFs proposed?\n",
    "    FP_list = defaultdict(int) # proposed UDFs\n",
    "    FN_list = defaultdict(int) # gt UDFs\n",
    "    num_proposed_udfs = 0\n",
    "    num_gt_new_udfs = 0\n",
    "    for num_new_udfs in num_new_udf_list:\n",
    "        avg_num_proposed_udfs = []\n",
    "        for query_class_name in query_class_names:\n",
    "            for run_id in run_ids:\n",
    "                for question_id in question_ids:\n",
    "                    proposed_udfs = []\n",
    "                    try:\n",
    "                        with open(os.path.join(config['output_dir'], \"udf_generation\", dataset, query_class_name, f\"num_missing_udfs={num_new_udfs}\", vocal_udf_config_name, f\"qid={question_id}-run={run_id}.json\"), \"r\") as f:\n",
    "                            data = json.load(f)\n",
    "                        proposed_udfs.extend(data[\"on_the_fly_udf_names\"])\n",
    "                        proposed_udfs.extend(data[\"materialized_df_names\"])\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                    if len(proposed_udfs) > 0 and num_new_udfs == 0:\n",
    "                        print(f\"query_class_name={query_class_name}, question_id={question_id}, run_id={run_id}\")\n",
    "                    num_proposed_udfs += len(proposed_udfs)\n",
    "                    num_gt_new_udfs += num_new_udfs\n",
    "                    avg_num_proposed_udfs.append(len(proposed_udfs))\n",
    "                    input_query_file = os.path.join(config[\"data_dir\"], dataset, f\"{query_class_name}.json\")\n",
    "                    input_query = json.load(open(input_query_file, \"r\"))[\"questions\"][question_id]\n",
    "                    new_modules = input_query[\"new_modules\"]\n",
    "                    gt_udfs = new_modules[(len(new_modules) - num_new_udfs):]\n",
    "                    for proposed_udf in proposed_udfs:\n",
    "                        if standardize_udf_name(dataset, proposed_udf) not in [gt_udf.replace(\" \", \"\").replace(\"_\", \"\").lower() for gt_udf in gt_udfs]:\n",
    "                            FP_list[proposed_udf] += 1\n",
    "\n",
    "                    for gt_udf in gt_udfs:\n",
    "                        if gt_udf.replace(\" \", \"\").replace(\"_\", \"\").lower() not in [standardize_udf_name(dataset, proposed_udf) for proposed_udf in proposed_udfs]:\n",
    "                            FN_list[gt_udf] += 1\n",
    "                            if gt_udf == \"SITTINGON\":\n",
    "                                print(f\"FN: query_class_name={query_class_name}, question_id={question_id}, run_id={run_id}\")\n",
    "\n",
    "        avg_num_proposed_udfs = np.mean(avg_num_proposed_udfs)\n",
    "        print(f\"num_new_udfs={num_new_udfs}: {avg_num_proposed_udfs}\")\n",
    "\n",
    "    # FP: over-proposed\n",
    "    # FN: under-proposed\n",
    "    print(\"FP: over-proposed\")\n",
    "    for udf_name, count in sorted(FP_list.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{udf_name}: {count}\")\n",
    "    print(f\"#FP={sum(FP_list.values())}\")\n",
    "    print(\"FN: under-proposed\")\n",
    "    for udf_name, count in sorted(FN_list.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{udf_name}: {count}\")\n",
    "    print(f\"#FN={sum(FN_list.values())}\")\n",
    "    print(\"num_proposed_udfs:\", num_proposed_udfs)\n",
    "    print(\"num_gt_new_udfs:\", num_gt_new_udfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_class_name=3_new_udfs_labels, question_id=25, run_id=2\n",
      "num_new_udfs=0: 0.011111111111111112\n",
      "num_new_udfs=1: 0.6111111111111112\n",
      "num_new_udfs=2: 1.5888888888888888\n",
      "num_new_udfs=3: 2.688888888888889\n",
      "FP: over-proposed\n",
      "behind_and_left_of: 6\n",
      "location_bottom_left: 6\n",
      "moves_in_front_of: 5\n",
      "made_of_metal: 2\n",
      "moving_in_front_of: 2\n",
      "location_right: 2\n",
      "left_of_first: 1\n",
      "left_of_second: 1\n",
      "in_front_of: 1\n",
      "made_of_rubber: 1\n",
      "#FP=27\n",
      "FN: under-proposed\n",
      "RIGHTOF: 49\n",
      "BEHIND: 35\n",
      "RIGHT: 10\n",
      "BOTTOM: 9\n",
      "NEAR: 9\n",
      "CYLINDER: 6\n",
      "FAR: 6\n",
      "METAL: 2\n",
      "#FN=126\n",
      "num_proposed_udfs: 441\n",
      "num_gt_new_udfs: 540\n"
     ]
    }
   ],
   "source": [
    "dataset = \"clevrer\"\n",
    "query_class_names = [\n",
    "    \"3_new_udfs_labels\",\n",
    "]\n",
    "question_ids = list(range(30))\n",
    "run_ids = list(range(3))\n",
    "num_new_udf_list = [0, 1, 2, 3]\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=True-pretrained_models=False-ntrain_distill=100-nselection_samples=500-selection=both-budget=20-llm_method=gpt\"\n",
    "\n",
    "eval_proposing_udfs(dataset, query_class_names, num_new_udf_list, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_new_udfs=0: 0.0\n",
      "num_new_udfs=1: 0.9666666666666667\n",
      "num_new_udfs=2: 1.9333333333333333\n",
      "FP: over-proposed\n",
      "moves_in_front_of: 3\n",
      "white_sedan: 1\n",
      "#FP=4\n",
      "FN: under-proposed\n",
      "INFRONTOF: 12\n",
      "TOTHERIGHTOF: 1\n",
      "TOTHELEFTOF: 1\n",
      "#FN=14\n",
      "num_proposed_udfs: 261\n",
      "num_gt_new_udfs: 270\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cityflow\"\n",
    "query_class_names = [\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=1-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\",\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=2-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\"\n",
    "]\n",
    "question_ids = list(range(15))\n",
    "run_ids = list(range(3))\n",
    "num_new_udf_list = [0, 1, 2]\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt\"\n",
    "\n",
    "eval_proposing_udfs(dataset, query_class_names, num_new_udf_list, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=2, run_id=0\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=0, run_id=1\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=0, run_id=2\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=2, run_id=2\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=4, run_id=2\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2, question_id=9, run_id=0\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2, question_id=9, run_id=1\n",
      "query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2, question_id=9, run_id=2\n",
      "query_class_name=unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2, question_id=5, run_id=1\n",
      "query_class_name=unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2, question_id=8, run_id=1\n",
      "num_new_udfs=0: 0.1111111111111111\n",
      "FN: query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=1, run_id=0\n",
      "FN: query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=1, run_id=1\n",
      "FN: query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=1, run_id=2\n",
      "num_new_udfs=1: 0.8\n",
      "FN: query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=1, run_id=0\n",
      "FN: query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=1, run_id=1\n",
      "FN: query_class_name=unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2, question_id=1, run_id=2\n",
      "FN: query_class_name=unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2, question_id=1, run_id=0\n",
      "FN: query_class_name=unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2, question_id=1, run_id=1\n",
      "FN: query_class_name=unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2, question_id=1, run_id=2\n",
      "num_new_udfs=2: 1.6333333333333333\n",
      "FP: over-proposed\n",
      "inside: 12\n",
      "above_and_behind: 5\n",
      "moving_behind: 1\n",
      "beneath_person: 1\n",
      "#FP=19\n",
      "FN: under-proposed\n",
      "BEHIND: 23\n",
      "BENEATH: 13\n",
      "SITTINGON: 9\n",
      "HOLDING: 5\n",
      "CARRYING: 5\n",
      "STANDINGON: 3\n",
      "COVEREDBY: 2\n",
      "#FN=60\n",
      "num_proposed_udfs: 229\n",
      "num_gt_new_udfs: 270\n"
     ]
    }
   ],
   "source": [
    "dataset = \"charades\"\n",
    "query_class_names = [\n",
    "    # \"unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2\",\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2\",\n",
    "    # \"unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2\"\n",
    "]\n",
    "question_ids = list(range(3))\n",
    "run_ids = list(range(1))\n",
    "num_new_udf_list = [0, 1, 2]\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-budget=50-llm_method=gpt\"\n",
    "\n",
    "eval_proposing_udfs(dataset, query_class_names, num_new_udf_list, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correctly_proposed(dataset, udf_name, gt_udfs):\n",
    "    udf_name = standardize_udf_name(dataset, udf_name)\n",
    "    if udf_name not in [gt_udf.replace(\" \", \"\").replace(\"_\", \"\").lower() for gt_udf in gt_udfs]:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_selection_strategy(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name):\n",
    "    \"\"\" Only evaluate correctly proposed UDFs\"\"\"\n",
    "    num_incorrect_proposal = 0\n",
    "    # UDF selection stats\n",
    "    num_correct_selection = 0\n",
    "    num_correct_selection_80 = 0\n",
    "    num_incorrect_selection = 0\n",
    "\n",
    "    # Choosing between UDF types stats (when 'dummy' is the only best UDF type)\n",
    "    num_correct_udf_type_dummy = 0 # The number of times the selected UDF type is correct\n",
    "    num_incorrect_udf_type_dummy = 0 # The number of times the selected UDF type is incorrect\n",
    "    num_llm_decides_program_udf_type_dummy = 0 # The number of times the LLM-selected UDF type is program\n",
    "    num_llm_decides_model_udf_type_dummy = 0 # The number of times the LLM-selected UDF type is model\n",
    "\n",
    "    # Choosing between UDF types stats (when the best UDF types are not 'dummy')\n",
    "    num_correct_udf_type_not_dummy = 0\n",
    "    num_incorrect_udf_type_not_dummy = 0\n",
    "    num_llm_decides_correct_udf_type_not_dummy = 0\n",
    "    num_llm_decides_incorrect_udf_type_not_dummy = 0\n",
    "\n",
    "    for query_class_name in query_class_names:\n",
    "        for run_id in run_ids:\n",
    "            for question_id in question_ids:\n",
    "                try:\n",
    "                    input_query_file = os.path.join(config[\"data_dir\"], dataset, f\"{query_class_name}.json\")\n",
    "                    input_query = json.load(open(input_query_file, \"r\"))[\"questions\"][question_id]\n",
    "                    new_modules = input_query[\"new_modules\"]\n",
    "                    gt_udfs = new_modules\n",
    "\n",
    "                    with open(os.path.join(config['output_dir'], \"best_udf_type\", dataset, query_class_name, vocal_udf_config_name, f\"qid={question_id}-run={run_id}.json\"), \"r\") as f:\n",
    "                        best_udf_type_data = json.load(f)\n",
    "                    for udf_name, v in best_udf_type_data.items():\n",
    "                        if not is_correctly_proposed(dataset, udf_name, gt_udfs):\n",
    "                            num_incorrect_proposal += 1\n",
    "                            continue\n",
    "                        if v[\"best_test_score\"] == v[\"selected_test_score\"]:\n",
    "                            num_correct_selection += 1\n",
    "                        else:\n",
    "                            num_incorrect_selection += 1\n",
    "\n",
    "                        if v[\"selected_test_score\"] >= 0.8 * v[\"best_test_score\"]:\n",
    "                            num_correct_selection_80 += 1\n",
    "\n",
    "                        if \"dummy\" not in v[\"best_udf_types\"] or (\"dummy\" in v[\"best_udf_types\"] and len(v[\"best_udf_types\"]) > 1):\n",
    "                            if v[\"selected_udf_type\"] in v[\"best_udf_types\"]:\n",
    "                                num_correct_udf_type_not_dummy += 1\n",
    "                            else:\n",
    "                                num_incorrect_udf_type_not_dummy += 1\n",
    "                        else:\n",
    "                            assert len(v[\"best_udf_types\"]) == 1, \"assert 1\"\n",
    "                            if v[\"selected_udf_type\"] == \"dummy\":\n",
    "                                num_correct_udf_type_dummy += 1\n",
    "                            else:\n",
    "                                num_incorrect_udf_type_dummy += 1\n",
    "                    with open(os.path.join(config['output_dir'], \"llm_decides_udf_type\", dataset, query_class_name, vocal_udf_config_name, \"gpt-4-turbo-2024-04-09\", f\"qid={question_id}-run={run_id}.json\"), \"r\") as f:\n",
    "                        llm_decides_udf_type_data = json.load(f)\n",
    "                    for udf_name, llm_decides_udf_type in llm_decides_udf_type_data.items():\n",
    "                        if udf_name not in best_udf_type_data:\n",
    "                            continue\n",
    "                        if not is_correctly_proposed(dataset, udf_name, gt_udfs):\n",
    "                            continue\n",
    "                        if \"dummy\" not in best_udf_type_data[udf_name][\"best_udf_types\"] or (\"dummy\" in best_udf_type_data[udf_name][\"best_udf_types\"] and len(best_udf_type_data[udf_name][\"best_udf_types\"]) > 1):\n",
    "                            if llm_decides_udf_type in best_udf_type_data[udf_name][\"best_udf_types\"]:\n",
    "                                num_llm_decides_correct_udf_type_not_dummy += 1\n",
    "                            else:\n",
    "                                num_llm_decides_incorrect_udf_type_not_dummy += 1\n",
    "                        else:\n",
    "                            if llm_decides_udf_type == \"program\":\n",
    "                                num_llm_decides_program_udf_type_dummy += 1\n",
    "                            elif llm_decides_udf_type == \"model\":\n",
    "                                num_llm_decides_model_udf_type_dummy += 1\n",
    "                            else:\n",
    "                                raise ValueError(f\"llm_decides_udf_type={llm_decides_udf_type}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}, query_class_name={query_class_name}, question_id={question_id}, run_id={run_id}\")\n",
    "\n",
    "    print(f\"num_incorrect_proposal={num_incorrect_proposal}\")\n",
    "\n",
    "    print(f\"num_correct_selection={num_correct_selection}, num_incorrect_selection={num_incorrect_selection}, ratio={num_correct_selection/(num_correct_selection+num_incorrect_selection)}, num_correct_selection_80={num_correct_selection_80}, ratio={num_correct_selection_80/(num_correct_selection+num_incorrect_selection)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"[When the best UDF types are not 'dummy']\")\n",
    "    print(f\"num_correct_udf_type_not_dummy={num_correct_udf_type_not_dummy}, num_incorrect_udf_type_not_dummy={num_incorrect_udf_type_not_dummy}, ratio={num_correct_udf_type_not_dummy/(num_correct_udf_type_not_dummy+num_incorrect_udf_type_not_dummy)}\")\n",
    "    print(f\"num_llm_decides_correct_udf_type_not_dummy={num_llm_decides_correct_udf_type_not_dummy}, num_llm_decides_incorrect_udf_type_not_dummy={num_llm_decides_incorrect_udf_type_not_dummy}, ratio={num_llm_decides_correct_udf_type_not_dummy/(num_llm_decides_correct_udf_type_not_dummy+num_llm_decides_incorrect_udf_type_not_dummy)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"[When 'dummy' is the only best UDF type]\")\n",
    "    print(f\"num_correct_udf_type_dummy={num_correct_udf_type_dummy}, num_incorrect_udf_type_dummy={num_incorrect_udf_type_dummy}, ratio={num_correct_udf_type_dummy/(num_correct_udf_type_dummy+num_incorrect_udf_type_dummy) if num_correct_udf_type_dummy+num_incorrect_udf_type_dummy > 0 else 0}\")\n",
    "    print(f\"num_llm_decides_program_udf_type_dummy={num_llm_decides_program_udf_type_dummy}, num_llm_decides_model_udf_type_dummy={num_llm_decides_model_udf_type_dummy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_incorrect_proposal=10\n",
      "num_correct_selection=163, num_incorrect_selection=69, ratio=0.7025862068965517, num_correct_selection_80=218, ratio=0.9396551724137931\n",
      "\n",
      "[When the best UDF types are not 'dummy']\n",
      "num_correct_udf_type_not_dummy=203, num_incorrect_udf_type_not_dummy=22, ratio=0.9022222222222223\n",
      "num_llm_decides_correct_udf_type_not_dummy=145, num_llm_decides_incorrect_udf_type_not_dummy=80, ratio=0.6444444444444445\n",
      "\n",
      "[When 'dummy' is the only best UDF type]\n",
      "num_correct_udf_type_dummy=3, num_incorrect_udf_type_dummy=4, ratio=0.42857142857142855\n",
      "num_llm_decides_program_udf_type_dummy=3, num_llm_decides_model_udf_type_dummy=4\n"
     ]
    }
   ],
   "source": [
    "dataset = \"clevrer\"\n",
    "query_class_names = [\n",
    "    \"3_new_udfs_labels\",\n",
    "]\n",
    "question_ids = list(range(30))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=True-pretrained_models=False-ntrain_distill=100-nselection_samples=500-selection=both-labels=user-budget=20-llm_method=gpt4v\"\n",
    "\n",
    "eval_selection_strategy(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_incorrect_proposal=0\n",
      "num_correct_selection=144, num_incorrect_selection=30, ratio=0.8275862068965517, num_correct_selection_80=154, ratio=0.8850574712643678\n",
      "\n",
      "[When the best UDF types are not 'dummy']\n",
      "num_correct_udf_type_not_dummy=154, num_incorrect_udf_type_not_dummy=20, ratio=0.8850574712643678\n",
      "num_llm_decides_correct_udf_type_not_dummy=102, num_llm_decides_incorrect_udf_type_not_dummy=72, ratio=0.5862068965517241\n",
      "\n",
      "[When 'dummy' is the only best UDF type]\n",
      "num_correct_udf_type_dummy=0, num_incorrect_udf_type_dummy=0, ratio=0\n",
      "num_llm_decides_program_udf_type_dummy=0, num_llm_decides_model_udf_type_dummy=0\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cityflow\"\n",
    "query_class_names = [\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=1-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\",\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=2-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\"\n",
    "]\n",
    "question_ids = list(range(15))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "\n",
    "eval_selection_strategy(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_incorrect_proposal=2\n",
      "num_correct_selection=93, num_incorrect_selection=52, ratio=0.6413793103448275, num_correct_selection_80=123, ratio=0.8482758620689655\n",
      "\n",
      "[When the best UDF types are not 'dummy']\n",
      "num_correct_udf_type_not_dummy=90, num_incorrect_udf_type_not_dummy=35, ratio=0.72\n",
      "num_llm_decides_correct_udf_type_not_dummy=57, num_llm_decides_incorrect_udf_type_not_dummy=68, ratio=0.456\n",
      "\n",
      "[When 'dummy' is the only best UDF type]\n",
      "num_correct_udf_type_dummy=18, num_incorrect_udf_type_dummy=2, ratio=0.9\n",
      "num_llm_decides_program_udf_type_dummy=1, num_llm_decides_model_udf_type_dummy=19\n"
     ]
    }
   ],
   "source": [
    "dataset = \"charades\"\n",
    "query_class_names = [\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2\",\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2\",\n",
    "    \"unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2\"\n",
    "]\n",
    "question_ids = list(range(10))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "\n",
    "eval_selection_strategy(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDF type stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_udf_type_stats(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name):\n",
    "    num_missing_udfs = 3 if dataset == \"clevrer\" else 2\n",
    "    num_dummy, num_program, num_model = 0, 0, 0\n",
    "    dummy_names = []\n",
    "    num_files = 0\n",
    "    for query_class_name in query_class_names:\n",
    "        for run_id in run_ids:\n",
    "            for question_id in question_ids:\n",
    "                try:\n",
    "                    input_query_file = os.path.join(config[\"data_dir\"], dataset, f\"{query_class_name}.json\")\n",
    "                    input_query = json.load(open(input_query_file, \"r\"))[\"questions\"][question_id]\n",
    "                    new_modules = input_query[\"new_modules\"]\n",
    "                    gt_udfs = new_modules\n",
    "                    with open(os.path.join(config['output_dir'], \"udf_generation\", dataset, query_class_name, f\"num_missing_udfs={num_missing_udfs}\", vocal_udf_config_name, f\"qid={question_id}-run={run_id}.json\"), \"r\") as f:\n",
    "                        data = json.load(f)\n",
    "                    num_files += 1\n",
    "                    for udf in data[\"registered_functions\"]:\n",
    "                        if \"semantic_interpretation\" in udf:\n",
    "                            udf_name = udf[\"signature\"].split(\"(\")[0]\n",
    "                            if not is_correctly_proposed(dataset, udf_name, gt_udfs):\n",
    "                                continue\n",
    "                            if udf[\"semantic_interpretation\"] == \"dummy\":\n",
    "                                num_dummy += 1\n",
    "                                dummy_names.append(udf_name)\n",
    "                            elif udf[\"semantic_interpretation\"] == \"model\":\n",
    "                                num_model += 1\n",
    "                            elif udf[\"function_implementation\"] != \"\":\n",
    "                                num_program += 1\n",
    "                            else:\n",
    "                                raise ValueError(f\"Unknown semantic_interpretation: {udf['semantic_interpretation']}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}, query_class_name={query_class_name}, question_id={question_id}, run_id={run_id}\")\n",
    "    print(f\"num_program={num_program}, num_model={num_model}, num_dummy={num_dummy}, num_files={num_files}\")\n",
    "    num_all = num_dummy + num_program + num_model\n",
    "    print(f\"program percentage: {num_program / num_all:.2f}, model percentage: {num_model / num_all:.2f}, dummy percentage: {num_dummy / num_all:.2f}\")\n",
    "    print(f\"dummy names: {sorted(dummy_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clevrer\n",
      "num_program=183, num_model=37, num_dummy=13, num_files=90\n",
      "program percentage: 0.79, model percentage: 0.16, dummy percentage: 0.06\n",
      "dummy names: ['behind', 'behind', 'behind', 'behind', 'behind', 'color_yellow', 'location_bottom', 'material_metal', 'material_metal', 'material_metal', 'material_metal', 'right_of', 'right_of']\n",
      "CityFlow\n",
      "num_program=94, num_model=76, num_dummy=4, num_files=90\n",
      "program percentage: 0.54, model percentage: 0.44, dummy percentage: 0.02\n",
      "dummy names: ['black', 'black', 'black', 'black']\n",
      "Charades\n",
      "num_program=81, num_model=23, num_dummy=41, num_files=90\n",
      "program percentage: 0.56, model percentage: 0.16, dummy percentage: 0.28\n",
      "dummy names: ['behind', 'behind', 'carrying', 'carrying', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'holding', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside', 'inside']\n"
     ]
    }
   ],
   "source": [
    "# Clevrer\n",
    "print(\"Clevrer\")\n",
    "dataset = \"clevrer\"\n",
    "query_class_names = [\n",
    "    \"3_new_udfs_labels\",\n",
    "]\n",
    "question_ids = list(range(30))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=True-pretrained_models=False-ntrain_distill=100-nselection_samples=500-selection=both-labels=user-budget=20-llm_method=gpt4v\"\n",
    "eval_udf_type_stats(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)\n",
    "\n",
    "# CityFlow\n",
    "print(\"CityFlow\")\n",
    "dataset = \"cityflow\"\n",
    "query_class_names = [\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=1-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\",\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=2-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\"\n",
    "]\n",
    "question_ids = list(range(15))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "eval_udf_type_stats(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)\n",
    "\n",
    "# Charades\n",
    "print(\"Charades\")\n",
    "dataset = \"charades\"\n",
    "query_class_names = [\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2\",\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2\",\n",
    "    \"unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2\"\n",
    "]\n",
    "question_ids = list(range(10))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "eval_udf_type_stats(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program-based UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_program_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name):\n",
    "    \"\"\" Only evaluate correctly proposed UDFs\"\"\"\n",
    "    best_program_types_when_best_is_program = defaultdict(int)\n",
    "    best_program_types_when_best_is_not_program = defaultdict(int)\n",
    "    f1_scores_when_best_is_program = []\n",
    "    f1_scores_when_best_is_not_program = []\n",
    "    best_f1_scores_when_best_is_program = []\n",
    "    best_f1_scores_when_best_is_not_program = []\n",
    "    test_count_program = 0\n",
    "    test_count_not_program = 0\n",
    "    for query_class_name in query_class_names:\n",
    "        for run_id in run_ids:\n",
    "            for question_id in question_ids:\n",
    "                try:\n",
    "                    input_query_file = os.path.join(config[\"data_dir\"], dataset, f\"{query_class_name}.json\")\n",
    "                    input_query = json.load(open(input_query_file, \"r\"))[\"questions\"][question_id]\n",
    "                    new_modules = input_query[\"new_modules\"]\n",
    "                    gt_udfs = new_modules\n",
    "\n",
    "                    with open(os.path.join(config['output_dir'], \"best_udf_type\", dataset, query_class_name, vocal_udf_config_name, f\"qid={question_id}-run={run_id}.json\"), \"r\") as f:\n",
    "                        best_udf_type_data = json.load(f)\n",
    "                    for udf_name, v in best_udf_type_data.items():\n",
    "                        if not is_correctly_proposed(dataset, udf_name, gt_udfs):\n",
    "                            continue\n",
    "                        candidates = v[\"candidates\"]\n",
    "                        if \"program\" in v[\"best_udf_types\"]:\n",
    "                            best_program_types_set = set([\"base\"])\n",
    "                            test_count_program += 1\n",
    "                            for best_udf_id in v[\"best_udf_ids\"]:\n",
    "                                if candidates[best_udf_id][\"udf_type\"] == \"program\":\n",
    "                                    for p in candidates[best_udf_id][\"program_types\"]:\n",
    "                                        best_program_types_set.add(p)\n",
    "                                        # best_program_types_when_best_is_program[p] += 1\n",
    "                                        # best_program_types_when_best_is_program[\"base\"] += 1\n",
    "                            for p in best_program_types_set:\n",
    "                                best_program_types_when_best_is_program[p] += 1\n",
    "                            for udf_id, udf_dict in candidates.items():\n",
    "                                if udf_dict[\"udf_type\"] == \"program\":\n",
    "                                    f1_scores_when_best_is_program.append(udf_dict[\"test_score\"])\n",
    "                            best_f1_scores_when_best_is_program.append(v[\"best_test_score\"])\n",
    "                        else:\n",
    "                            test_count_not_program += 1\n",
    "                            best_program_score = -1\n",
    "                            best_program_types = set()\n",
    "                            for udf_id, udf_dict in candidates.items():\n",
    "                                if udf_dict[\"udf_type\"] == \"program\":\n",
    "                                    f1_scores_when_best_is_not_program.append(udf_dict[\"test_score\"])\n",
    "                                    if udf_dict[\"test_score\"] > best_program_score:\n",
    "                                        best_program_score = udf_dict[\"test_score\"]\n",
    "                                        best_program_types = set(udf_dict[\"program_types\"])\n",
    "                                        best_program_types.add(\"base\")\n",
    "                                    elif udf_dict[\"test_score\"] == best_program_score:\n",
    "                                        best_program_types.update(udf_dict[\"program_types\"])\n",
    "                                        best_program_types.add(\"base\")\n",
    "                            for p in best_program_types:\n",
    "                                best_program_types_when_best_is_not_program[p] += 1\n",
    "                            best_f1_scores_when_best_is_not_program.append(best_program_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}, query_class_name={query_class_name}, question_id={question_id}, run_id={run_id}\")\n",
    "    print(f\"test_count_program={test_count_program}, test_count_not_program={test_count_not_program}\")\n",
    "    print(\"[when best is program]\")\n",
    "    print(\"best_program_types\")\n",
    "    for k, v in sorted(best_program_types_when_best_is_program.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(f\"best_f1_scores: 25 percentile={np.percentile(best_f1_scores_when_best_is_program, 25)}, 50 percentile={np.percentile(best_f1_scores_when_best_is_program, 50)}, 75 percentile={np.percentile(best_f1_scores_when_best_is_program, 75)}\")\n",
    "    print(f\"f1_scores: 25 percentile={np.percentile(f1_scores_when_best_is_program, 25)}, 50 percentile={np.percentile(f1_scores_when_best_is_program, 50)}, 75 percentile={np.percentile(f1_scores_when_best_is_program, 75)}\")\n",
    "    print()\n",
    "    print(\"[when best is not program]\")\n",
    "    print(\"best_program_types\")\n",
    "    for k, v in sorted(best_program_types_when_best_is_not_program.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(f\"best_f1_scores: 25 percentile={np.percentile(best_f1_scores_when_best_is_not_program, 25)}, 50 percentile={np.percentile(best_f1_scores_when_best_is_not_program, 50)}, 75 percentile={np.percentile(best_f1_scores_when_best_is_not_program, 75)}\")\n",
    "    print(f\"f1_scores: 25 percentile={np.percentile(f1_scores_when_best_is_not_program, 25)}, 50 percentile={np.percentile(f1_scores_when_best_is_not_program, 50)}, 75 percentile={np.percentile(f1_scores_when_best_is_not_program, 75)}\")\n",
    "    print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clevrer\n",
      "test_count_program=195, test_count_not_program=37\n",
      "[when best is program]\n",
      "best_program_types\n",
      "base: 195\n",
      "parameter: 59\n",
      "reuse: 52\n",
      "pixel: 40\n",
      "best_f1_scores: 25 percentile=0.881683897402995, 50 percentile=0.9943457189014541, 75 percentile=0.99989964866964\n",
      "f1_scores: 25 percentile=0.0007183292470223369, 50 percentile=0.20382901584572233, 75 percentile=0.6703282425288524\n",
      "\n",
      "[when best is not program]\n",
      "best_program_types\n",
      "base: 37\n",
      "parameter: 14\n",
      "pixel: 12\n",
      "reuse: 8\n",
      "best_f1_scores: 25 percentile=0.5197317111215098, 50 percentile=0.6663110162710056, 75 percentile=0.715272611329578\n",
      "f1_scores: 25 percentile=0.0, 50 percentile=0.024043627188344976, 75 percentile=0.29208441701024235\n",
      "\n",
      "\n",
      "CityFlow\n",
      "test_count_program=83, test_count_not_program=91\n",
      "[when best is program]\n",
      "best_program_types\n",
      "base: 83\n",
      "reuse: 25\n",
      "parameter: 14\n",
      "best_f1_scores: 25 percentile=1.0, 50 percentile=1.0, 75 percentile=1.0\n",
      "f1_scores: 25 percentile=0.5633505679213657, 50 percentile=0.8295834595811007, 75 percentile=0.9523411348420604\n",
      "\n",
      "[when best is not program]\n",
      "best_program_types\n",
      "base: 91\n",
      "reuse: 90\n",
      "parameter: 16\n",
      "best_f1_scores: 25 percentile=0.34552332912988654, 50 percentile=0.34930291508238276, 75 percentile=0.4065947620654252\n",
      "f1_scores: 25 percentile=0.053690343614325606, 50 percentile=0.20289144817446703, 75 percentile=0.28997773343732797\n",
      "\n",
      "\n",
      "Charades\n",
      "test_count_program=70, test_count_not_program=75\n",
      "[when best is program]\n",
      "best_program_types\n",
      "base: 70\n",
      "reuse: 32\n",
      "parameter: 15\n",
      "best_f1_scores: 25 percentile=0.9602312256343218, 50 percentile=1.0, 75 percentile=1.0\n",
      "f1_scores: 25 percentile=0.01845549916433136, 50 percentile=0.09215193920571145, 75 percentile=0.35671144250090375\n",
      "\n",
      "[when best is not program]\n",
      "best_program_types\n",
      "base: 75\n",
      "reuse: 33\n",
      "parameter: 28\n",
      "best_f1_scores: 25 percentile=0.08714798951136288, 50 percentile=0.16200748404138235, 75 percentile=0.5625383581777299\n",
      "f1_scores: 25 percentile=0.002526992878474615, 50 percentile=0.030428769017980636, 75 percentile=0.10995670995670995\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clevrer\n",
    "print(\"Clevrer\")\n",
    "dataset = \"clevrer\"\n",
    "query_class_names = [\n",
    "    \"3_new_udfs_labels\",\n",
    "]\n",
    "question_ids = list(range(30))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=True-pretrained_models=False-ntrain_distill=100-nselection_samples=500-selection=both-labels=user-budget=20-llm_method=gpt4v\"\n",
    "eval_program_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)\n",
    "\n",
    "# CityFlow\n",
    "print(\"CityFlow\")\n",
    "dataset = \"cityflow\"\n",
    "query_class_names = [\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=1-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\",\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=2-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\"\n",
    "]\n",
    "question_ids = list(range(15))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "eval_program_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)\n",
    "\n",
    "# Charades\n",
    "print(\"Charades\")\n",
    "dataset = \"charades\"\n",
    "query_class_names = [\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2\",\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2\",\n",
    "    \"unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2\"\n",
    "]\n",
    "question_ids = list(range(10))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "eval_program_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distilled-model UDFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name):\n",
    "    \"\"\" Only evaluate correctly proposed UDFs\"\"\"\n",
    "    f1_scores_when_best_is_model = []\n",
    "    f1_scores_when_best_is_not_model = []\n",
    "    dummy_f1_scores_when_best_is_model = []\n",
    "    dummy_f1_scores_when_best_is_not_model = []\n",
    "\n",
    "    for query_class_name in query_class_names:\n",
    "        for run_id in run_ids:\n",
    "            for question_id in question_ids:\n",
    "                try:\n",
    "                    input_query_file = os.path.join(config[\"data_dir\"], dataset, f\"{query_class_name}.json\")\n",
    "                    input_query = json.load(open(input_query_file, \"r\"))[\"questions\"][question_id]\n",
    "                    new_modules = input_query[\"new_modules\"]\n",
    "                    gt_udfs = new_modules\n",
    "\n",
    "                    with open(os.path.join(config['output_dir'], \"best_udf_type\", dataset, query_class_name, vocal_udf_config_name, f\"qid={question_id}-run={run_id}.json\"), \"r\") as f:\n",
    "                        best_udf_type_data = json.load(f)\n",
    "                    for udf_name, v in best_udf_type_data.items():\n",
    "                        if not is_correctly_proposed(dataset, udf_name, gt_udfs):\n",
    "                            continue\n",
    "                        candidates = v[\"candidates\"]\n",
    "                        if \"model\" in v[\"best_udf_types\"]:\n",
    "                            f1_scores_when_best_is_model.append(v[\"best_test_score\"])\n",
    "                            for udf_id, udf_dict in candidates.items():\n",
    "                                if udf_dict[\"udf_type\"] == \"dummy\":\n",
    "                                    dummy_f1_scores_when_best_is_model.append(udf_dict[\"test_score\"])\n",
    "                                    break\n",
    "                        else:\n",
    "                            for udf_id, udf_dict in candidates.items():\n",
    "                                if udf_dict[\"udf_type\"] == \"model\":\n",
    "                                    f1_scores_when_best_is_not_model.append(udf_dict[\"test_score\"])\n",
    "                                elif udf_dict[\"udf_type\"] == \"dummy\":\n",
    "                                    dummy_f1_scores_when_best_is_not_model.append(udf_dict[\"test_score\"])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}, query_class_name={query_class_name}, question_id={question_id}, run_id={run_id}\")\n",
    "    print(\"[when best is model]\")\n",
    "    print(f\"f1_scores: 25 percentile={np.percentile(f1_scores_when_best_is_model, 25)}, 50 percentile={np.percentile(f1_scores_when_best_is_model, 50)}, 75 percentile={np.percentile(f1_scores_when_best_is_model, 75)}\")\n",
    "    print(f\"dummy_f1_scores: 25 percentile={np.percentile(dummy_f1_scores_when_best_is_model, 25)}, 50 percentile={np.percentile(dummy_f1_scores_when_best_is_model, 50)}, 75 percentile={np.percentile(dummy_f1_scores_when_best_is_model, 75)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"[when best is not model]\")\n",
    "    print(f\"f1_scores: 25 percentile={np.percentile(f1_scores_when_best_is_not_model, 25)}, 50 percentile={np.percentile(f1_scores_when_best_is_not_model, 50)}, 75 percentile={np.percentile(f1_scores_when_best_is_not_model, 75)}\")\n",
    "    print(f\"dummy_f1_scores: 25 percentile={np.percentile(dummy_f1_scores_when_best_is_not_model, 25)}, 50 percentile={np.percentile(dummy_f1_scores_when_best_is_not_model, 50)}, 75 percentile={np.percentile(dummy_f1_scores_when_best_is_not_model, 75)}\")\n",
    "    print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clevrer\n",
      "[when best is model]\n",
      "f1_scores: 25 percentile=0.8636934401402501, 50 percentile=0.8878386632110703, 75 percentile=0.906326922131627\n",
      "dummy_f1_scores: 25 percentile=0.5120708192525893, 50 percentile=0.5193411047636953, 75 percentile=0.5240392146807388\n",
      "\n",
      "[when best is not model]\n",
      "f1_scores: 25 percentile=0.30358093358729504, 50 percentile=0.5590698001025888, 75 percentile=0.7341133060197836\n",
      "dummy_f1_scores: 25 percentile=0.22781435827522856, 50 percentile=0.6616702295532436, 75 percentile=0.6663999466559978\n",
      "\n",
      "\n",
      "CityFlow\n",
      "[when best is model]\n",
      "f1_scores: 25 percentile=0.542231736927161, 50 percentile=0.6868782567503553, 75 percentile=0.8096138847302035\n",
      "dummy_f1_scores: 25 percentile=0.2716902868994124, 50 percentile=0.28884325804243666, 75 percentile=0.3023491763835717\n",
      "\n",
      "[when best is not model]\n",
      "f1_scores: 25 percentile=0.6871171355979506, 50 percentile=0.732957012592271, 75 percentile=0.7926690260647395\n",
      "dummy_f1_scores: 25 percentile=0.6604152712659076, 50 percentile=0.6645299145299145, 75 percentile=0.6705663387396968\n",
      "\n",
      "\n",
      "Charades\n",
      "[when best is model]\n",
      "f1_scores: 25 percentile=0.2417876925620746, 50 percentile=0.7236593760408572, 75 percentile=0.7477503453918775\n",
      "dummy_f1_scores: 25 percentile=0.025177885112249457, 50 percentile=0.2072427393330943, 75 percentile=0.5891647785325338\n",
      "\n",
      "[when best is not model]\n",
      "f1_scores: 25 percentile=0.2620952596949457, 50 percentile=0.30207563888888966, 75 percentile=0.5756872081982736\n",
      "dummy_f1_scores: 25 percentile=0.5721679830721825, 50 percentile=0.7281398994670012, 75 percentile=0.929551066108405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clevrer\n",
    "print(\"Clevrer\")\n",
    "dataset = \"clevrer\"\n",
    "query_class_names = [\n",
    "    \"3_new_udfs_labels\",\n",
    "]\n",
    "question_ids = list(range(30))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=True-pretrained_models=False-ntrain_distill=100-nselection_samples=500-selection=both-labels=user-budget=20-llm_method=gpt4v\"\n",
    "eval_model_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)\n",
    "\n",
    "# CityFlow\n",
    "print(\"CityFlow\")\n",
    "dataset = \"cityflow\"\n",
    "query_class_names = [\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=1-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\",\n",
    "    \"unavailable_pred=1-unavailable_attr_pred=1-npred=2-nattr_pred=2-nvars=3-depth=3-max_duration=15-min_npos=74-max_npos=737\"\n",
    "]\n",
    "question_ids = list(range(15))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "eval_model_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)\n",
    "\n",
    "# Charades\n",
    "print(\"Charades\")\n",
    "dataset = \"charades\"\n",
    "query_class_names = [\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=3-depth=2\",\n",
    "    \"unavailable=2-npred=4-nobj_pred=1-nvars=2-depth=2\",\n",
    "    \"unavailable=2-npred=3-nobj_pred=1-nvars=2-depth=2\"\n",
    "]\n",
    "question_ids = list(range(10))\n",
    "run_ids = list(range(3))\n",
    "vocal_udf_config_name = \"ninterp=10-nparams=5-kwargs=True-pixels=False-pretrained_models=False-ntrain_distill=500-nselection_samples=500-selection=both-labels=user-budget=50-llm_method=gpt4v\"\n",
    "eval_model_udfs(dataset, query_class_names, question_ids, run_ids, vocal_udf_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset=cityflow\n",
      "[gpt4v] udf_name=suv, mean=0.843, std=0.008\n",
      "[gpt4v] udf_name=white, mean=0.906, std=0.004\n",
      "[gpt4v] udf_name=grey, mean=0.797, std=0.011\n",
      "[gpt4v] udf_name=van, mean=0.956, std=0.003\n",
      "[gpt4v] udf_name=sedan, mean=0.903, std=0.018\n",
      "[gpt4v] udf_name=black, mean=0.819, std=0.012\n",
      "[gpt4v] udf_name=red, mean=0.973, std=0.006\n",
      "[gpt4v] udf_name=blue, mean=0.904, std=0.001\n",
      "[gpt4v] udf_name=pickup_truck, mean=0.956, std=0.005\n",
      "\n",
      "dataset=charades\n",
      "[gpt4v] udf_name=holding, mean=0.776, std=0.022\n",
      "[gpt4v] udf_name=sitting_on, mean=0.896, std=0.003\n",
      "[gpt4v] udf_name=standing_on, mean=0.846, std=0.008\n",
      "[gpt4v] udf_name=covered_by, mean=0.749, std=0.016\n",
      "[gpt4v] udf_name=carrying, mean=0.761, std=0.004\n",
      "[gpt4v] udf_name=eating, mean=0.737, std=0.013\n",
      "[gpt4v] udf_name=wiping, mean=0.685, std=0.020\n",
      "[gpt4v] udf_name=touching, mean=0.632, std=0.021\n",
      "[gpt4v] udf_name=leaning_on, mean=0.816, std=0.018\n",
      "[gpt4v] udf_name=wearing, mean=0.854, std=0.011\n",
      "[gpt4v] udf_name=drinking_from, mean=0.916, std=0.015\n",
      "[gpt4v] udf_name=lying_on, mean=0.857, std=0.014\n",
      "[gpt4v] udf_name=writing_on, mean=0.894, std=0.010\n",
      "[gpt4v] udf_name=above, mean=0.683, std=0.011\n",
      "[gpt4v] udf_name=in_front_of, mean=0.644, std=0.004\n",
      "[gpt4v] udf_name=beneath, mean=0.561, std=0.010\n",
      "[gpt4v] udf_name=behind, mean=0.599, std=0.033\n",
      "[gpt4v] udf_name=in, mean=0.444, std=0.021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_labeling_quality(dataset):\n",
    "    if dataset == \"cityflow\":\n",
    "        udfs = [\"suv\", \"white\", \"grey\", \"van\", \"sedan\", \"black\", \"red\", \"blue\", \"pickup_truck\"]\n",
    "    elif dataset == \"charades\":\n",
    "        # removing \"have_it_on_the_back\" and \"twisting\" due to insufficient positives\n",
    "        udfs = [\"holding\", \"sitting_on\", \"standing_on\", \"covered_by\", \"carrying\", \"eating\", \"wiping\", \"touching\", \"leaning_on\", \"wearing\", \"drinking_from\", \"lying_on\", \"writing_on\", \"above\", \"in_front_of\", \"beneath\", \"behind\", \"in\"]\n",
    "    else:\n",
    "        raise ValueError(f\"dataset={dataset}\")\n",
    "\n",
    "    gpt4v_results = defaultdict(list)\n",
    "    for udf_name in udfs:\n",
    "        for run_id in range(3):\n",
    "            # random.seed(run_id)\n",
    "            # np.random.seed(run_id)\n",
    "            try:\n",
    "                with open(os.path.join(config[\"log_dir\"], \"labeling_quality\", dataset, \"balanced=True\", f\"udf_name={udf_name}-n_train_distill=500-llm_method=gpt4v-run_id={run_id}.log\"), \"r\") as f:\n",
    "                    lines = f.readlines()\n",
    "                    llm_f1 = -1\n",
    "                    npos, nneg = 0, 0\n",
    "                    for line in lines:\n",
    "                        if \"llm_f1: \" in line:\n",
    "                            # 2024-07-21 23:37:06,240 - vocaludf - DEBUG - llm_TP: 63, llm_FP: 47, llm_TN: 203, llm_FN: 187, llm_f1: 0.35\n",
    "                            pattern = r\"llm_TP: (\\d+), llm_FP: (\\d+), llm_TN: (\\d+), llm_FN: (\\d+), llm_f1: ([\\d.]+)\"\n",
    "                            match = re.search(pattern, line)\n",
    "                            llm_tp = int(match.group(1))\n",
    "                            llm_fp = int(match.group(2))\n",
    "                            llm_tn = int(match.group(3))\n",
    "                            llm_fn = int(match.group(4))\n",
    "                            llm_f1 = float(match.group(5))\n",
    "                            npos = llm_tp + llm_fn\n",
    "                            nneg = llm_fp + llm_tn\n",
    "                            # print(f\"llm_f1={llm_f1}, npos={npos}, nneg={nneg}\")\n",
    "                            # if npos != nneg:\n",
    "                            #     print(f\"not enough positives: udf_name={udf_name}, run_id={run_id}\")\n",
    "                            break\n",
    "                    if llm_f1 == -1:\n",
    "                        print(f\"failed task: udf_name={udf_name}, run_id={run_id}\")\n",
    "                        llm_f1 = 0\n",
    "                    gpt4v_results[udf_name].append(llm_f1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}, udf_name={udf_name}, run_id={run_id}\")\n",
    "\n",
    "    print(f\"dataset={dataset}\")\n",
    "    for udf_name, llm_f1s in gpt4v_results.items():\n",
    "        print(f\"[gpt4v] udf_name={udf_name}, mean={np.mean(llm_f1s):.3f}, std={np.std(llm_f1s):.3f}\")\n",
    "    print()\n",
    "\n",
    "eval_labeling_quality(\"cityflow\")\n",
    "eval_labeling_quality(\"charades\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocal-udf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
